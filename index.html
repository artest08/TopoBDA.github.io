<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TopoBDA: Bezier Deformable Attention for Road Topology</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Header Section -->
    <header class="hero">
        <div class="container">
            <div class="hero-content">
                <h1 class="hero-title">TopoBDA</h1>
                <p class="hero-subtitle">Towards Bezier Deformable Attention for Road Topology Understanding</p>
                <div class="authors">
                    <span class="author">Muhammet Esat Kalfaoglu*</span>
                    <span class="author">Halil Ibrahim Ozturk</span>
                    <span class="author">Ozsel Kilinc</span>
                    <span class="author">Alptekin Temizel</span>
                </div>
                <div class="affiliations">
                    <span class="affiliation">Middle East Technical University ‚Ä¢ Togg/Trutek AI Team</span>
                </div>
                <div class="action-buttons">
                    <a href="https://arxiv.org/abs/2412.18951" class="btn btn-primary" target="_blank">
                        üìÑ Paper
                    </a>
                    <a href="#citation" class="btn btn-secondary">
                        üìã Cite
                    </a>
                </div>
            </div>
        </div>
    </header>

    <!-- Abstract -->
    <section class="section" id="abstract">
        <div class="container">
            <h2>Abstract</h2>
            <div class="abstract-content">
                <p>
                    Understanding road topology is crucial for autonomous driving. This paper introduces <strong>TopoBDA</strong> 
                    (Topology with Bezier Deformable Attention), a novel approach that enhances road topology comprehension 
                    by leveraging Bezier Deformable Attention (BDA). TopoBDA processes multi-camera 360-degree imagery to 
                    generate Bird's Eye View (BEV) features, which are refined through a transformer decoder employing BDA. 
                    BDA utilizes Bezier control points to drive the deformable attention mechanism, improving the detection 
                    and representation of elongated and thin polyline structures, such as lane centerlines.
                </p>
                <p>
                    Additionally, TopoBDA integrates two auxiliary components: an instance mask formulation loss and a 
                    one-to-many set prediction loss strategy, to further refine centerline detection and enhance road 
                    topology understanding. Experimental evaluations on the OpenLane-V2 dataset demonstrate that TopoBDA 
                    outperforms existing methods, achieving state-of-the-art results in centerline detection and topology 
                    reasoning. TopoBDA also achieves the best results on the OpenLane-V1 dataset in 3D lane detection. 
                    Further experiments on integrating multi-modal data‚Äîsuch as LiDAR, radar, and SDMap‚Äîshow that multimodal 
                    inputs can further enhance performance in road topology understanding.
                </p>
            </div>
        </div>
    </section>

    <!-- Research Highlights -->
    <section class="section" id="highlights-research">
        <div class="container">
            <h2>Research Highlights</h2>
            <div class="highlights-research-grid">
                <div class="highlight-item">
                    <div class="highlight-icon">üîó</div>
                    <h3>Novel MPDA Integration to Bezier Structures</h3>
                    <p>First-time integration of Multi-Point Deformable Attention (MPDA) into Bezier keypoint-dependent transformer decoders, enhancing centerline detection for elongated polyline structures.</p>
                </div>
                <div class="highlight-item">
                    <div class="highlight-icon">üéØ</div>
                    <h3>Bezier Deformable Attention (BDA)</h3>
                    <p>Novel attention mechanism utilizing Bezier control points as reference points, achieving superior performance with reduced computational complexity compared to traditional MPDA approaches.</p>
                </div>
                <div class="highlight-item">
                    <div class="highlight-icon">üîß</div>
                    <h3>Instance Mask Formulation</h3>
                    <p>Indirect auxiliary supervision through instance mask prediction and Mask-L1 mix matcher, improving centerline detection without inference overhead.</p>
                </div>
                <div class="highlight-item">
                    <div class="highlight-icon">üåê</div>
                    <h3>Multi-modal Fusion Analysis</h3>
                    <p>First comprehensive evaluation of camera, LiDAR, radar, and SDMap integration for road topology understanding, achieving state-of-the-art multi-modal performance.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Architecture Overview -->
    <section class="section" id="architecture">
        <div class="container">
            <h2>Method Overview</h2>
            <div class="figure-container">
                <div class="image-container">
                    <img src="images/topoBDA.png" alt="TopoBDA Architecture - Multi-camera BEV feature extraction with Bezier Deformable Attention" class="research-figure architecture-figure" loading="lazy">
                </div>
                <div class="figure-caption">
                    <strong>Figure 1: TopoBDA Architecture.</strong> Multi-camera images are processed through BEV feature extraction, 
                    then refined using a transformer decoder with novel Bezier Deformable Attention to predict precise centerline instances.
                </div>
            </div>
        </div>
    </section>

    <!-- Key Innovation: Bezier Deformable Attention -->
    <section class="section" id="innovation">
        <div class="container">
            <h2>Key Innovation: Bezier Deformable Attention</h2>
            <div class="innovation-grid">
                <div class="innovation-item">
                    <h3>Attention Evolution</h3>
                    <div class="figure-container">
                        <div class="image-container">
                            <img src="images/spda_vs_mpda.png" alt="Attention Mechanism Evolution: SPDA to MPDA to BDA comparison" class="research-figure comparison-figure" loading="lazy">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 2: Attention Mechanism Evolution.</strong> From Single-Point (SPDA) to Multi-Point (MPDA) 
                            to our novel Bezier Deformable Attention (BDA) that directly uses control points.
                        </div>
                    </div>
                </div>
                <div class="innovation-item">
                    <h3>Implementation Efficiency</h3>
                    <div class="figure-container">
                        <div class="image-container">
                            <img src="images/msda_vs_bda.png" alt="BDA vs MPDA Implementation Efficiency Comparison" class="research-figure comparison-figure" loading="lazy">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 3: BDA vs MPDA Implementation.</strong> BDA eliminates matrix multiplication overhead by directly 
                            using Bezier control points as attention reference points.
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Methodology Section -->
    <section class="section" id="methodology">
        <div class="container">
            <h2>Methodology</h2>
            
            <div class="methodology-grid">
                <div class="method-card">
                    <h3>üèóÔ∏è Instance Query Architecture</h3>
                    <p>Multi-camera 360-degree imagery processed through BEV feature extraction, refined via transformer decoder with sparse query approach where each query represents a centerline instance rather than individual points.</p>
                </div>
                
                <div class="method-card">
                    <h3>üìê Bezier Control Point Regression</h3>
                    <p>Compact polyline representation through Bezier control points, enabling efficient centerline modeling via matrix multiplication operations while reducing computational complexity at regression heads.</p>
                </div>
                
                <div class="method-card">
                    <h3>üéØ Auxiliary Training Components</h3>
                    <p>Instance mask prediction and Mask-L1 mix matcher during training enhance centerline detection accuracy. One-to-many set prediction loss improves training convergence without inference overhead.</p>
                </div>
            </div>
            
            <!-- BDA Layers Visualization -->
            <div class="figure-container">
                <div class="image-container">
                    <img src="images/BDA_layers.png" alt="TopoBDA Layers with Bezier Deformable Attention - Iterative refinement across decoder layers" class="research-figure layers-figure" loading="lazy">
                </div>
                <div class="figure-caption">
                    <strong>Figure 6: BDA Layers Visualization.</strong> This figure shows the layers of TopoBDA, each driven by 
                    Bezier Deformable Attention (BDA) using control points predicted through iterative refinement. The iterative 
                    refinement process improves prediction accuracy across decoder layers.
                </div>
            </div>
        </div>
    </section>

    <!-- Experimental Results -->
    <section class="section" id="results">
        <div class="container">
            <h2>Experimental Results</h2>
            
            <!-- State-of-the-art Comparison -->
            <div class="results-container">
                <h3>üèÜ State-of-the-Art Performance on OpenLane-V2 (Subset-A)</h3>
                <div class="table-responsive">
                    <table class="performance-table">
                        <thead>
                            <tr>
                                <th>Method</th>
                                <th>Sensor</th>
                                <th>DET<sub>l</sub></th>
                                <th>DET<sub>t</sub></th>
                                <th>TOP<sub>ll</sub></th>
                                <th>TOP<sub>lt</sub></th>
                                <th>OLS</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>TopoNet</td>
                                <td>C</td>
                                <td>28.6</td>
                                <td>48.6</td>
                                <td>10.9</td>
                                <td>23.9</td>
                                <td>39.8</td>
                            </tr>
                            <tr>
                                <td>TopoMLP</td>
                                <td>C</td>
                                <td>28.5</td>
                                <td>49.5</td>
                                <td>21.7</td>
                                <td>26.9</td>
                                <td>44.1</td>
                            </tr>
                            <tr>
                                <td>TopoFormer</td>
                                <td>C</td>
                                <td>34.7</td>
                                <td>48.2</td>
                                <td>24.1</td>
                                <td>29.5</td>
                                <td>46.3</td>
                            </tr>
                            <tr>
                                <td>TopoMaskV2</td>
                                <td>C</td>
                                <td>34.5</td>
                                <td>53.8</td>
                                <td>24.5</td>
                                <td>35.6</td>
                                <td>49.4</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>C</strong></td>
                                <td><strong>38.9</strong></td>
                                <td><strong>54.3</strong></td>
                                <td><strong>27.6</strong></td>
                                <td><strong>37.3</strong></td>
                                <td><strong>51.7</strong></td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>C + L</strong></td>
                                <td><strong>47.3</strong></td>
                                <td><strong>54.0</strong></td>
                                <td><strong>35.5</strong></td>
                                <td><strong>41.9</strong></td>
                                <td><strong>56.4</strong></td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>C + SD</strong></td>
                                <td><strong>42.7</strong></td>
                                <td><strong>52.4</strong></td>
                                <td><strong>34.3</strong></td>
                                <td><strong>41.7</strong></td>
                                <td><strong>54.6</strong></td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>C + L + SD</strong></td>
                                <td><strong>52.0</strong></td>
                                <td><strong>52.4</strong></td>
                                <td><strong>38.5</strong></td>
                                <td><strong>45.3</strong></td>
                                <td><strong>58.4</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                
                <h3>üèÜ State-of-the-Art Performance on OpenLane-V1 (3D Lane Detection)</h3>
                <div class="table-responsive">
                    <table class="performance-table">
                        <thead>
                            <tr>
                                <th>Distance</th>
                                <th>Method</th>
                                <th>Backbone</th>
                                <th>F1-Score ‚Üë</th>
                                <th>X-error near (m) ‚Üì</th>
                                <th>X-error far (m) ‚Üì</th>
                                <th>Z-error near (m) ‚Üì</th>
                                <th>Z-error far (m) ‚Üì</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="border-bottom: 2px solid #ddd;">
                                <td rowspan="7" style="vertical-align: middle; font-weight: bold;">1.5m</td>
                                <td>PersFormer</td>
                                <td>ResNet-50</td>
                                <td>52.7</td>
                                <td>0.307</td>
                                <td>0.319</td>
                                <td>0.083</td>
                                <td>0.117</td>
                            </tr>
                            <tr>
                                <td>Anchor3DLane</td>
                                <td>ResNet-50</td>
                                <td>57.5</td>
                                <td>0.229</td>
                                <td><strong>0.243</strong></td>
                                <td>0.079</td>
                                <td>0.106</td>
                            </tr>
                            <tr>
                                <td>GroupLane</td>
                                <td>ResNet-50</td>
                                <td>60.2</td>
                                <td>0.371</td>
                                <td>0.476</td>
                                <td>0.220</td>
                                <td>0.357</td>
                            </tr>
                            <tr>
                                <td>LaneCPP</td>
                                <td>EffNet-B7</td>
                                <td>60.3</td>
                                <td>0.264</td>
                                <td>0.310</td>
                                <td>0.077</td>
                                <td>0.117</td>
                            </tr>
                            <tr>
                                <td>LATR</td>
                                <td>ResNet-50</td>
                                <td>61.9</td>
                                <td><strong>0.219</strong></td>
                                <td style="text-decoration: underline;">0.259</td>
                                <td style="text-decoration: underline;">0.075</td>
                                <td style="text-decoration: underline;">0.104</td>
                            </tr>
                            <tr>
                                <td>PVALane</td>
                                <td>ResNet-50</td>
                                <td style="text-decoration: underline;">62.7</td>
                                <td>0.232</td>
                                <td style="text-decoration: underline;">0.259</td>
                                <td>0.092</td>
                                <td>0.118</td>
                            </tr>
                            <tr class="highlight" style="border-bottom: 2px solid #ddd;">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>ResNet-50</strong></td>
                                <td><strong>63.9</strong></td>
                                <td style="text-decoration: underline;"><strong>0.224</strong></td>
                                <td><strong>0.243</strong></td>
                                <td><strong>0.069</strong></td>
                                <td><strong>0.101</strong></td>
                            </tr>
                            <tr>
                                <td rowspan="4" style="vertical-align: middle; font-weight: bold;">0.5m</td>
                                <td>PersFormer</td>
                                <td>ResNet-50</td>
                                <td>43.2</td>
                                <td>0.229</td>
                                <td>0.245</td>
                                <td>0.078</td>
                                <td>0.106</td>
                            </tr>
                            <tr>
                                <td>DV-3DLane</td>
                                <td>ResNet-34</td>
                                <td>52.9</td>
                                <td>0.173</td>
                                <td>0.212</td>
                                <td style="text-decoration: underline;">0.069</td>
                                <td style="text-decoration: underline;">0.098</td>
                            </tr>
                            <tr>
                                <td>LATR</td>
                                <td>ResNet-50</td>
                                <td style="text-decoration: underline;">54.0</td>
                                <td style="text-decoration: underline;">0.171</td>
                                <td style="text-decoration: underline;">0.201</td>
                                <td>0.072</td>
                                <td>0.099</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>TopoBDA (Ours)</strong></td>
                                <td><strong>ResNet-50</strong></td>
                                <td><strong>57.9</strong></td>
                                <td><strong>0.157</strong></td>
                                <td><strong>0.179</strong></td>
                                <td><strong>0.067</strong></td>
                                <td><strong>0.087</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3>Instance Mask Formulation Ablation</h3>
                <div class="table-responsive">
                    <table class="performance-table">
                        <thead>
                            <tr>
                                <th>IMAL</th>
                                <th>ML1M</th>
                                <th>DET<sub>l</sub></th>
                                <th>DET<sub>l_ch</sub></th>
                                <th>TOP<sub>ll</sub></th>
                                <th>OLS<sub>l</sub></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>‚úó</td>
                                <td>‚úó</td>
                                <td>37.0</td>
                                <td>39.8</td>
                                <td>29.0</td>
                                <td>43.6</td>
                            </tr>
                            <tr>
                                <td>‚úì</td>
                                <td>‚úó</td>
                                <td style="text-decoration: underline;">40.7</td>
                                <td style="text-decoration: underline;">42.1</td>
                                <td style="text-decoration: underline;">32.4</td>
                                <td style="text-decoration: underline;">46.6</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>‚úì</strong></td>
                                <td><strong>‚úì</strong></td>
                                <td><strong>40.8</strong></td>
                                <td><strong>45.8</strong></td>
                                <td><strong>32.9</strong></td>
                                <td><strong>48.0</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="table-caption">
                        <strong>IMAL</strong>: Instance Mask Auxiliary Loss | <strong>ML1M</strong>: Mask-L1 Mix Matcher<br>
                        Results show significant improvements from instance mask formulation: +3.7 points in DET<sub>l</sub> and +3.3 points in OLS<sub>l</sub> with IMAL.
                    </p>
                </div>

                <h3>Attention Mechanism Ablation</h3>
                <div class="table-responsive">
                    <table class="performance-table">
                        <thead>
                            <tr>
                                <th>Attention Type</th>
                                <th>DET<sub>l</sub></th>
                                <th>DET<sub>l_ch</sub></th>
                                <th>TOP<sub>ll</sub></th>
                                <th>OLS<sub>l</sub></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>SA (Standard Attention)</td>
                                <td>34.5</td>
                                <td>38.4</td>
                                <td>25.1</td>
                                <td>41.0</td>
                            </tr>
                            <tr>
                                <td>MA (Masked Attention)</td>
                                <td>35.8</td>
                                <td>40.2</td>
                                <td>26.9</td>
                                <td>42.6</td>
                            </tr>
                            <tr>
                                <td>SPDA (Single-Point Deformable Attention)</td>
                                <td>38.3</td>
                                <td>39.8</td>
                                <td>29.5</td>
                                <td>44.1</td>
                            </tr>
                            <tr>
                                <td>MPDA4 (Multi-Point Deformable Attention)</td>
                                <td>40.2</td>
                                <td>45.0</td>
                                <td>32.6</td>
                                <td>47.4</td>
                            </tr>
                            <tr>
                                <td>MPDA16 (16-Point Deformable Attention)</td>
                                <td style="text-decoration: underline;">40.3</td>
                                <td style="text-decoration: underline;">45.1</td>
                                <td style="text-decoration: underline;">32.7</td>
                                <td style="text-decoration: underline;">47.5</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>BDA (Bezier Deformable Attention)</strong></td>
                                <td><strong>40.8</strong></td>
                                <td><strong>45.8</strong></td>
                                <td><strong>32.9</strong></td>
                                <td><strong>48.0</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    </section>

    <!-- Visual Results -->
    <section class="section" id="visual-results">
        <div class="container">
            <h2>Visual Results</h2>
            
            <!-- Closed-loop and Fusion Analysis -->
            <div class="figure-container">
                <div class="image-container">
                    <img src="images/clsd_fuse_analysis.png" alt="TopoBDA Closed-loop Analysis and Multi-modal Fusion Results" class="research-figure analysis-figure" loading="lazy">
                </div>
                <div class="figure-caption">
                    <strong>Figure 5: Multi-modal Fusion Analysis.</strong> Comprehensive performance analysis demonstrating the impact 
                    of different sensor modalities (Camera, LiDAR, Radar) and SDMap integration in multi-modal fusion scenarios. 
                    TopoBDA achieves superior performance across all multi-modal evaluation configurations, showing the effectiveness 
                    of sensor fusion for road topology understanding.
                </div>
            </div>

            <!-- Dataset Overview -->
            <div class="figure-container">
                <div class="image-container">
                    <img src="images/dataset.png" alt="OpenLane-V2 Dataset Overview - Perspective and Bird's Eye View samples with annotations" class="research-figure dataset-figure" loading="lazy">
                </div>
                <div class="figure-caption">
                    <strong>Figure 7: Dataset Ground Truth Visualization.</strong> OpenLane-V2 dataset samples showing perspective view (PV) and 
                    bird's eye view (BEV) with ground truth annotations for centerline detection and topological relationships. 
                    This figure displays the reference annotations used for training and evaluation, not model predictions.
                </div>
            </div>
        </div>
    </section>

    <!-- Conclusion -->
    <section class="section" id="conclusion">
        <div class="container">
            <h2>Conclusion</h2>
            <div class="conclusion-content">
                <p>
                    Experimental evaluations demonstrate that <strong>TopoBDA achieves state-of-the-art performance</strong> 
                    across both subsets of the OpenLane-V2 dataset. Specifically, TopoBDA surpasses existing methods with a 
                    <strong>DET<sub>l</sub> score of 38.9</strong> and an <strong>OLS score of 51.7</strong> in Subset-A, 
                    and a <strong>DET<sub>l</sub> score of 45.1</strong> and an <strong>OLS score of 54.3</strong> in Subset-B.
                </p>
                <p>
                    The integration of multi-modal data significantly boosts performance: fusing camera and LiDAR data increases 
                    the OLS score in Subset-A from <strong>51.7 to 56.4</strong>, and in Subset-B from <strong>54.3 to 61.7</strong>. 
                    Further incorporating SDMap alongside camera and LiDAR sensors raises the OLS score in Subset-A to <strong>58.4</strong>. 
                    These results underscore the effectiveness of TopoBDA in road topology comprehension and highlight the substantial 
                    benefits of multi-modal fusion.
                </p>
                <p>
                    Additionally, TopoBDA achieves superior results on the OpenLane-V1 benchmark for 3D lane detection, with 
                    F1-scores of <strong>63.9</strong> at a 1.5m distance and <strong>57.9</strong> at a 0.5m distance. 
                    This work contributes toward closing existing gaps in HDMap element prediction, offering a unified framework 
                    for road topology understanding and 3D lane detection in autonomous driving.
                </p>
            </div>
        </div>
    </section>

    <!-- Citation Section -->
    <section class="section" id="citation">
        <div class="container">
            <h2>Citation</h2>
            <div class="citation-box">
                <pre id="citation-text">@article{kalfaoglu2024topobda,
  title={TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding},
  author={Kalfaoglu, Muhammet Esat and Ozturk, Halil Ibrahim and Kilinc, Ozsel and Temizel, Alptekin},
  journal={Neurocomputing},
  year={2024},
  publisher={Elsevier}
}</pre>
                <button class="copy-btn" onclick="copyToClipboard()">üìã Copy Citation</button>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2024 TopoBDA Research. All rights reserved.</p>
            <p>üìß Contact: <a href="mailto:esat.kalfaoglu@metu.edu.tr">esat.kalfaoglu@metu.edu.tr</a></p>
        </div>
    </footer>

    <!-- Image Modal -->
    <div id="imageModal" class="image-modal">
        <span class="close">&times;</span>
        <img id="modalImage" src="" alt="">
    </div>

    <script src="script.js"></script>
</body>
</html>
