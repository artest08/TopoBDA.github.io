<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>TopoBDA</h1>
            <p class="subtitle">Towards Bezier Deformable Attention for Road Topology Understanding</p>
            <p class="authors">
                <span class="author">Muhammet Esat Kalfaoglu</span><sup>1,2</sup>, 
                <span class="author">Halil Ibrahim Ozturk</span><sup>2</sup>, 
                <span class="author">Ozsel Kilinc</span><sup>2</sup>, 
                <span class="author">Alptekin Temizel</span><sup>1</sup>
            </p>
            <p class="affiliations">
                <sup>1</sup>Middle East Technical University &nbsp;&nbsp;&nbsp; <sup>2</sup>Togg/Trutek AI Team
            </p>
            <nav>
                <a href="#abstract">Abstract</a>
                <a href="#method">Method</a>
                <a href="#results">Results</a>
                <a href="#comparison">Comparison</a>
                <a href="#paper">Paper</a>
            </nav>
        </div>
    </header>

    <main class="container">
        <section id="hero">
            <div class="hero-content">
                <h2>State-of-the-Art Road Topology Understanding with Bezier Deformable Attention</h2>
                <p>TopoBDA introduces a novel Bezier Deformable Attention mechanism for enhanced centerline detection and road topology understanding in autonomous driving. Our method achieves state-of-the-art results on OpenLane-V1 and OpenLane-V2 datasets through innovative attention mechanisms and multi-modal sensor fusion.</p>
                <div class="buttons">
                    <a href="TopoBDA_neurocomputing.pdf" class="btn btn-primary" target="_blank">üìÑ Read Paper</a>
                    <a href="#method" class="btn btn-secondary">üîç Learn More</a>
                </div>
            </div>
        </section>

        <section id="abstract">
            <h2>Abstract</h2>
            <p>
                Understanding road topology is crucial for autonomous driving. This paper introduces TopoBDA (Topology with Bezier Deformable Attention), a novel approach that enhances road topology comprehension by leveraging Bezier Deformable Attention (BDA). TopoBDA processes multi-camera 360-degree imagery to generate Bird's Eye View (BEV) features, which are refined through a transformer decoder employing BDA. BDA utilizes Bezier control points to drive the deformable attention mechanism, improving the detection and representation of elongated and thin polyline structures, such as lane centerlines.
            </p>
            <p>
                Additionally, TopoBDA integrates two auxiliary components: an instance mask formulation loss and a one-to-many set prediction loss strategy, to further refine centerline detection and enhance road topology understanding. Experimental evaluations on the OpenLane-V2 dataset demonstrate that TopoBDA outperforms existing methods, achieving state-of-the-art results in centerline detection and topology reasoning. TopoBDA also achieves the best results on the OpenLane-V1 dataset in 3D lane detection.
            </p>

            <div class="highlights">
                <h3>Research Highlights</h3>
                <ul>
                    <li><strong>Novel MPDA integration</strong> into Bezier regression improves road topology understanding</li>
                    <li><strong>Bezier Deformable Attention</strong> enhances road topology understanding with minimal computational overhead</li>
                    <li><strong>Instance mask formulation</strong> boosts road topology understanding performance</li>
                    <li><strong>Multi-modal fusion</strong> achieves state-of-the-art road topology understanding</li>
                    <li><strong>One-to-many set prediction loss</strong> analyzed for road topology understanding for the first time</li>
                </ul>
            </div>
        </section>

        <section id="method">
            <h2>Method Overview</h2>
            <div class="method-overview">
                <p>TopoBDA enhances road topology understanding through a novel Bezier Deformable Attention mechanism. The architecture processes multi-camera 360-degree imagery to extract Bird's Eye View features, which are then refined using a transformer decoder with our proposed attention mechanism.</p>
            </div>
            
            <div class="method-grid">
                <div class="method-item">
                    <h3>TopoBDA Architecture</h3>
                    <div class="pdf-viewer">
                        <embed src="images/topoBDA.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/topoBDA.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Overview of the TopoBDA architecture based on instance query concept. BEV features from multiple camera images are fed into the transformer decoder, which outputs Bezier control points converted into centerline instances via matrix multiplication.
                    </p>
                </div>

                <div class="method-item">
                    <h3>Attention Mechanisms Comparison</h3>
                    <div class="pdf-viewer">
                        <embed src="images/attention_types.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/attention_types.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Comparison of various cross-attention mechanisms within the decoder architecture for polyline structures, including our novel Bezier Deformable Attention (BDA).
                    </p>
                </div>

                <div class="method-item">
                    <h3>BDA Layers Architecture</h3>
                    <div class="pdf-viewer">
                        <embed src="images/BDA_layers.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/BDA_layers.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Detailed view of the Bezier Deformable Attention layers and their integration within the transformer decoder architecture.
                    </p>
                </div>

                <div class="method-item">
                    <h3>SPDA vs MPDA Analysis</h3>
                    <div class="pdf-viewer">
                        <embed src="images/spda_vs_mpda.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/spda_vs_mpda.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Comparative analysis between Single-Point Deformable Attention (SPDA) and Multi-Point Deformable Attention (MPDA) mechanisms.
                    </p>
                </div>

                <div class="method-item">
                    <h3>Multi-Modal Sensor Fusion</h3>
                    <div class="pdf-viewer">
                        <embed src="images/sensor_fusion.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/sensor_fusion.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Integration strategy for multi-modal sensor data including camera, LiDAR, radar, and SDMap for enhanced road topology understanding.
                    </p>
                </div>

                <div class="method-item">
                    <h3>Mask Head Implementation</h3>
                    <div class="pdf-viewer">
                        <embed src="images/mask_head.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/mask_head.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="method-description">
                        Instance mask formulation architecture used as auxiliary loss to enhance centerline detection performance.
                    </p>
                </div>
            </div>
        </section>

        <section id="results">
            <h2>Experimental Results</h2>
            <div class="results-overview">
                <p>Our experimental evaluation demonstrates the effectiveness of TopoBDA across multiple benchmarks. We conduct comprehensive ablation studies on attention mechanisms, instance mask formulation, sensor fusion, and compare against state-of-the-art methods on OpenLane-V1 and OpenLane-V2 datasets.</p>
            </div>

            <div class="results-grid">
                <div class="result-item">
                    <h3>Dataset Visualization</h3>
                    <div class="pdf-viewer">
                        <embed src="images/dataset.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/dataset.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="result-description">
                        Perspective-view (PV) and bird's-eye-view (BEV) samples from the OpenLane-V2 dataset showing centerline instances and topological relationships.
                    </p>
                </div>

                <div class="result-item">
                    <h3>Multi-View Perspective Samples</h3>
                    <div class="pdf-viewer">
                        <embed src="images/all_views_pv_samples.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/all_views_pv_samples.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="result-description">
                        Comprehensive multi-view perspective samples demonstrating the complexity of road topology understanding across different viewpoints.
                    </p>
                </div>

                <div class="result-item">
                    <h3>Bird's Eye View Samples</h3>
                    <div class="pdf-viewer">
                        <embed src="images/bev_samples.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/bev_samples.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="result-description">
                        BEV domain visualization showing the effectiveness of our approach in detecting and understanding road topology structures.
                    </p>
                </div>

                <div class="result-item">
                    <h3>MSDA vs BDA Comparison</h3>
                    <div class="pdf-viewer">
                        <embed src="images/msda_vs_bda.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/msda_vs_bda.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="result-description">
                        Comparative analysis between Multi-Scale Deformable Attention (MSDA) and our proposed Bezier Deformable Attention (BDA) mechanism.
                    </p>
                </div>

                <div class="result-item">
                    <h3>Closed-Loop Fusion Analysis</h3>
                    <div class="pdf-viewer">
                        <embed src="images/clsd_fuse_analysis.pdf" type="application/pdf" width="100%" height="400">
                        <p><a href="images/clsd_fuse_analysis.pdf" target="_blank">View Full Size</a></p>
                    </div>
                    <p class="result-description">
                        Visual demonstration showing the impact of LiDAR and SDMap integration with camera sensors in the BEV domain for enhanced performance.
                    </p>
                </div>
            </div>

            <div class="performance-tables">
                <h3>Key Performance Results</h3>
                
                <div class="table-container">
                    <h4>Impact of Instance Mask Formulation (OpenLane-V2 Subset-A)</h4>
                    <table class="results-table">
                        <thead>
                            <tr>
                                <th>IMAL</th>
                                <th>ML1M</th>
                                <th>DET<sub>l</sub></th>
                                <th>DET<sub>l_ch</sub></th>
                                <th>TOP<sub>ll</sub></th>
                                <th>OLS<sub>l</sub></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>-</td>
                                <td>-</td>
                                <td>37.0</td>
                                <td>39.8</td>
                                <td>29.0</td>
                                <td>43.6</td>
                            </tr>
                            <tr class="highlight">
                                <td>‚úì</td>
                                <td>-</td>
                                <td>40.7</td>
                                <td>42.1</td>
                                <td>32.4</td>
                                <td>46.6</td>
                            </tr>
                            <tr class="best">
                                <td>‚úì</td>
                                <td>‚úì</td>
                                <td><strong>40.8</strong></td>
                                <td><strong>45.8</strong></td>
                                <td><strong>32.9</strong></td>
                                <td><strong>48.0</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="table-note">IMAL: Instance Mask Auxiliary Loss, ML1M: Mask-L1 Mix Matcher</p>
                </div>

                <div class="table-container">
                    <h4>Sensor Fusion Results (OpenLane-V2)</h4>
                    <table class="results-table">
                        <thead>
                            <tr>
                                <th>Subset</th>
                                <th>Configuration</th>
                                <th>DET<sub>l</sub></th>
                                <th>DET<sub>l_ch</sub></th>
                                <th>TOP<sub>ll</sub></th>
                                <th>OLS<sub>l</sub></th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td rowspan="5">A</td>
                                <td>Camera</td>
                                <td>38.9</td>
                                <td>39.2</td>
                                <td>29.4</td>
                                <td>44.1</td>
                            </tr>
                            <tr>
                                <td>Camera + SDMap</td>
                                <td>42.7</td>
                                <td>48.0</td>
                                <td>35.7</td>
                                <td>50.1</td>
                            </tr>
                            <tr>
                                <td>Camera + LiDAR</td>
                                <td>46.5</td>
                                <td>49.0</td>
                                <td>36.7</td>
                                <td>52.0</td>
                            </tr>
                            <tr class="highlight">
                                <td>Camera + LiDAR‚Ä†</td>
                                <td>47.3</td>
                                <td>51.2</td>
                                <td>37.3</td>
                                <td>53.2</td>
                            </tr>
                            <tr class="best">
                                <td>Camera + LiDAR‚Ä† + SDMap</td>
                                <td><strong>52.0</strong></td>
                                <td><strong>52.8</strong></td>
                                <td><strong>40.0</strong></td>
                                <td><strong>56.0</strong></td>
                            </tr>
                            <tr>
                                <td rowspan="4">B</td>
                                <td>Camera</td>
                                <td>45.1</td>
                                <td>45.1</td>
                                <td>35.6</td>
                                <td>49.9</td>
                            </tr>
                            <tr>
                                <td>Camera + Radar</td>
                                <td>49.4</td>
                                <td>52.8</td>
                                <td>38.6</td>
                                <td>54.8</td>
                            </tr>
                            <tr class="highlight">
                                <td>Camera + LiDAR</td>
                                <td>57.5</td>
                                <td>59.4</td>
                                <td>46.0</td>
                                <td>61.6</td>
                            </tr>
                            <tr class="best">
                                <td>Camera + LiDAR‚Ä†</td>
                                <td><strong>57.7</strong></td>
                                <td><strong>60.0</strong></td>
                                <td><strong>46.7</strong></td>
                                <td><strong>62.0</strong></td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="table-note">‚Ä† Configuration with LiDAR encoder (SECOND)</p>
                </div>
            </div>
        </section>

        <section id="comparison">
            <h2>State-of-the-Art Comparison</h2>
            <div class="comparison-overview">
                <p>TopoBDA achieves state-of-the-art results on both OpenLane-V1 and OpenLane-V2 datasets, demonstrating superior performance in centerline detection and road topology understanding across various evaluation metrics.</p>
            </div>

            <div class="sota-results">
                <div class="sota-item">
                    <h3>OpenLane-V2 Performance</h3>
                    <p class="performance-highlight">
                        üèÜ <strong>State-of-the-art results</strong> achieved on OpenLane-V2 dataset with camera-only and multi-modal configurations
                    </p>
                    <ul class="achievement-list">
                        <li><strong>Camera-only:</strong> Best performance in centerline detection metrics</li>
                        <li><strong>Multi-modal:</strong> Superior results with LiDAR + Camera + SDMap fusion</li>
                        <li><strong>Topology reasoning:</strong> Enhanced understanding of road connectivity</li>
                    </ul>
                </div>

                <div class="sota-item">
                    <h3>OpenLane-V1 Performance</h3>
                    <p class="performance-highlight">
                        ü•á <strong>Best results</strong> on OpenLane-V1 dataset for 3D lane detection
                    </p>
                    <ul class="achievement-list">
                        <li><strong>F1 Score:</strong> Superior performance in 3D lane detection</li>
                        <li><strong>Distance accuracy:</strong> Improved precision at various detection ranges</li>
                        <li><strong>Robustness:</strong> Better performance across different weather conditions</li>
                    </ul>
                </div>
            </div>

            <div class="key-innovations">
                <h3>Key Technical Innovations</h3>
                <div class="innovations-grid">
                    <div class="innovation-item">
                        <h4>üéØ Bezier Deformable Attention</h4>
                        <p>Novel attention mechanism using Bezier control points for improved polyline structure detection with minimal computational overhead.</p>
                    </div>
                    <div class="innovation-item">
                        <h4>üîó Multi-Point Deformable Attention</h4>
                        <p>First integration of MPDA into Bezier keypoint-dependent transformer decoders for enhanced centerline detection.</p>
                    </div>
                    <div class="innovation-item">
                        <h4>üé≠ Instance Mask Formulation</h4>
                        <p>Auxiliary loss strategy that improves centerline detection performance through indirect mask supervision.</p>
                    </div>
                    <div class="innovation-item">
                        <h4>üåê Multi-Modal Fusion</h4>
                        <p>First comprehensive evaluation of sensor fusion (LiDAR, radar, SDMap) specifically for road topology understanding.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="paper">
            <h2>Publication & Resources</h2>
            <div class="paper-section">
                <div class="paper-info">
                    <h3>üìÑ Full Paper</h3>
                    <p class="paper-title">TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding</p>
                    <p class="journal-info">Published in <strong>Neurocomputing</strong>, 2025</p>
                    <p class="paper-description">
                        Read the complete research paper for detailed methodology, comprehensive experiments, ablation studies, and theoretical analysis of our novel Bezier Deformable Attention mechanism.
                    </p>
                    <div class="paper-actions">
                        <a href="TopoBDA_neurocomputing.pdf" class="btn btn-primary btn-large" target="_blank">
                            üìÑ Download PDF
                        </a>
                        <a href="#abstract" class="btn btn-secondary">
                            üìã View Abstract
                        </a>
                    </div>
                </div>

                <div class="citation-section">
                    <h4>üìù Citation</h4>
                    <div class="citation-box">
                        <pre><code>@article{kalfaoglu2025topobda,
    title={TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding},
    author={Kalfaoglu, Muhammet Esat and Ozturk, Halil Ibrahim and Kilinc, Ozsel and Temizel, Alptekin},
    journal={Neurocomputing},
    year={2025},
    publisher={Elsevier}
}</code></pre>
                        <button class="copy-btn" onclick="copyToClipboard()">üìã Copy Citation</button>
                    </div>
                </div>

                <div class="keywords-section">
                    <h4>üîç Keywords</h4>
                    <div class="keywords">
                        <span class="keyword">Road Topology Understanding</span>
                        <span class="keyword">Centerline Detection</span>
                        <span class="keyword">Autonomous Driving</span>
                        <span class="keyword">Automated HDMap Generation</span>
                        <span class="keyword">3D Lane Detection</span>
                        <span class="keyword">Bezier Deformable Attention</span>
                        <span class="keyword">Multi-Modal Fusion</span>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 TopoBDA Research Project. All rights reserved.</p>
            <p><strong>TopoBDA: Towards Bezier Deformable Attention for Road Topology Understanding</strong></p>
            <p>Middle East Technical University ‚Ä¢ Togg/Trutek AI Team</p>
            <div class="footer-links">
                <a href="TopoBDA_neurocomputing.pdf" target="_blank">Paper</a>
                <a href="mailto:esat.kalfaoglu@metu.edu.tr">Contact</a>
                <a href="https://github.com/artest08/TopoBDA.github.io" target="_blank">GitHub</a>
            </div>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>
